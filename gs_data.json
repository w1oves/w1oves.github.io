{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "i5W4i9YAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "zhixiang wei", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=i5W4i9YAAAAJ&citpid=1", "affiliation": "university of science and technology of china", "organization": 8123924430127665534, "interests": ["computer vision", "semantic segmentation"], "email_domain": "@mail.ustc.edu.cn", "homepage": "http://zxwei.site/", "citedby": 406, "publications": {"i5W4i9YAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Reusing the task-specific classifier as a discriminator: Discriminator-free adversarial domain adaptation", "pub_year": "2022"}, "filled": false, "author_pub_id": "i5W4i9YAAAAJ:9yKSN-GCB0IC", "num_citations": 237, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3673441406066018173", "cites_id": ["3673441406066018173"]}, "i5W4i9YAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Stronger, Fewer, & Superior: Harnessing Vision Foundation Models for Domain Generalized Semantic Segmentation", "pub_year": "2024"}, "filled": false, "author_pub_id": "i5W4i9YAAAAJ:Y0pCki6q_DkC", "num_citations": 88, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18312121541513055596", "cites_id": ["18312121541513055596"]}, "i5W4i9YAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Deliberated domain bridging for domain adaptive semantic segmentation", "pub_year": "2022"}, "filled": false, "author_pub_id": "i5W4i9YAAAAJ:2osOgNQ5qMEC", "num_citations": 49, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12908675739985569858", "cites_id": ["12908675739985569858"]}, "i5W4i9YAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Disentangle then parse: Night-time semantic segmentation with illumination disentanglement", "pub_year": "2023"}, "filled": false, "author_pub_id": "i5W4i9YAAAAJ:UeHWp8X0CEIC", "num_citations": 18, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6636094140356247295", "cites_id": ["6636094140356247295"]}, "i5W4i9YAAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Crossearth: Geospatial vision foundation model for domain generalizable remote sensing semantic segmentation", "pub_year": "2024"}, "filled": false, "author_pub_id": "i5W4i9YAAAAJ:0EnyYjriUFMC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10812296569122070280", "cites_id": ["10812296569122070280"]}, "i5W4i9YAAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Masked pre-training enables universal zero-shot denoiser", "pub_year": "2024"}, "filled": false, "author_pub_id": "i5W4i9YAAAAJ:5nxA0vEk-isC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8862340236586251129", "cites_id": ["8862340236586251129"]}, "i5W4i9YAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Seed Optimization With Frozen Generator for Superior Zero-Shot Low-Light Image Enhancement", "pub_year": "2024"}, "filled": false, "author_pub_id": "i5W4i9YAAAAJ:LkGwnXOMwfcC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4139381497214855761", "cites_id": ["4139381497214855761"]}, "i5W4i9YAAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Improving Visual and Downstream Performance of Low-Light Enhancer with Vision Foundation Models Collaboration", "pub_year": "2025"}, "filled": false, "author_pub_id": "i5W4i9YAAAAJ:MXK_kJrjxJIC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12710165954860226498", "cites_id": ["12710165954860226498"]}, "i5W4i9YAAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Physical prior-guided deep learning for SIM reconstruction: modeling object-to-image degradation", "pub_year": "2024"}, "filled": false, "author_pub_id": "i5W4i9YAAAAJ:Se3iqnhoufwC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14563870543567614740", "cites_id": ["14563870543567614740"]}, "i5W4i9YAAAAJ:KlAtU1dfN6UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rein++: Efficient Generalization and Adaptation for Semantic Segmentation with Vision Foundation Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "i5W4i9YAAAAJ:KlAtU1dfN6UC", "num_citations": 0}, "i5W4i9YAAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "HQ-CLIP: Leveraging Large Vision-Language Models to Create High-Quality Image-Text Datasets and CLIP Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "i5W4i9YAAAAJ:kNdYIx-mwKoC", "num_citations": 0}, "i5W4i9YAAAAJ:3fE2CSJIrl8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Data and Prior-Driven Low-Light Enhancement Boosting the Visibility of Imaging Systems", "pub_year": "2025"}, "filled": false, "author_pub_id": "i5W4i9YAAAAJ:3fE2CSJIrl8C", "num_citations": 0}, "i5W4i9YAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Domain Adaptative Video Semantic Segmentation via Motion-Guided Domain Bridge", "pub_year": "2024"}, "filled": false, "author_pub_id": "i5W4i9YAAAAJ:hqOjcs7Dif8C", "num_citations": 0}, "i5W4i9YAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Masked Pre-trained Model Enables Universal Zero-shot Denoiser", "pub_year": "2024"}, "filled": false, "author_pub_id": "i5W4i9YAAAAJ:roLk4NBRz8UC", "num_citations": 0}}, "citedby5y": 406, "hindex": 5, "hindex5y": 5, "i10index": 4, "i10index5y": 4, "cites_per_year": {"2022": 6, "2023": 62, "2024": 164, "2025": 172}, "updated": "2025-09-20 08:23:04.186506"}