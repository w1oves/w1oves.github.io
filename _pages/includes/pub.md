
# üìù Publications 
*(\* denotes equal contribution.)*


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2025</div><img src='images/iccv25.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

### First Author
[HQCLIP: Leveraging Vision-Language Models to Create High-Quality Image-Text Datasets and CLIP Models](https://arxiv.org/abs/2507.22431) \\

[**Zhixiang Wei**](https://zxwei.site)\*, [Guangting Wang](https://scholar.google.com/citations?user=cKY8e8sAAAAJ&hl=zh-CN)\*, [Xiaoxiao Ma](https://krennic999.github.io/), et al.

GitHub comming soon

- We generated detailed, bidirectional long-text descriptions for **1.3 billion** images and pretrained/fine-tuned CLIP based on this dataset. Building upon this foundation, we propose a novel CLIP training framework that combines both bidirectional supervision and label classification losses. This framework achieves SoTA results on zero-shot classification, retrieval, and other tasks at the same data scale.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/rein.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

### First Author
[Stronger, Fewer, & Superior: Harnessing Vision Foundation Models for Domain Generalized Semantic Segmentation](https://arxiv.org/pdf/2312.04265.pdf) \\
[**Zhixiang Wei**](https://zxwei.site)\*, [Lin Chen](https://lin-chen.site/)\*, Yi Jin\*, [Xiaoxiao Ma](https://krennic999.github.io/), et al.

[[Project page](https://zxwei.site/rein/)]  [![](https://img.shields.io/github/stars/w1oves/Rein?style=social&label=Rein+Stars)](https://github.com/w1oves/Rein) <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:qjMakFHDy7sC'></span></strong>

- We propose the Reins framework, which efficiently fine-tunes vision foundation models for the domain generalized semantic segmentation (DGSS) task with just 1% trainable parameters, surprisingly surpassing full parameter fine-tuning. And Reins builds a new SOTA in various DGSS benchmarks.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/dtp.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

### First Author
[Disentangle then Parse: Night-time Semantic Segmentation with Illumination Disentanglement](https://arxiv.org/pdf/2307.09362.pdf) \\
[**Zhixiang Wei**](https://zxwei.site)\*, [Lin Chen](https://lin-chen.site/)\*, et al.

[![](https://img.shields.io/github/stars/w1oves/DTP?style=social&label=DTP+Stars)](https://github.com/w1oves/DTP)
  - We propose a novel nigh-time semantic segmentation paradigm, i.e., disentangle then parse (DTP), which explicitly disentangles night-time images into light-invariant reflectance and light-specific illumination components and then recognizes semantics based on their adaptive fusion.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2022 <span style="color:yellow">(Spotlight)</span></div><img src='images/ddb.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

### Co-First Author
[Deliberated Domain Bridging for Domain Adaptive Semantic Segmentation](https://arxiv.org/pdf/2209.07695.pdf) \\
[Lin Chen](https://lin-chen.site/)\*, [**Zhixiang Wei**](https://zxwei.site)\*, [Xin Jin](https://www.eitech.edu.cn/?tid=40&p=teacher)\*, et al.

[![](https://img.shields.io/github/stars/xiaoachen98/DDB?style=social&label=DDB+Stars)](https://github.com/xiaoachen98/DDB)
- We leverage the complementary characteristics of the coarse-wise and fine-wise data mixing techniques to progressively transfer the knowledge from the source to the target domain.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024</div><img src='images/MPI.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

### Co-First Author
[Masked Pre-trained Model Enables Universal Zero-shot Denoiser](https://arxiv.org/abs/2401.14966) \\
, [Xiaoxiao Ma](https://krennic999.github.io/)\*, [**Zhixiang Wei**](https://zxwei.site)\*, et al.  

[![](https://img.shields.io/github/stars/walker-hyf/ECSS?style=social&label=Code+Stars)](https://github.com/krennic999/MPI)
- MPI is a zero-shot denoising pipeline designed for many types of noise degradations.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2022</div><img src='images/daln.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

### Co-Author
[Reusing the Task-specific Classifier as a Discriminator: Discriminator-free Adversarial Domain Adaptation](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Reusing_the_Task-Specific_Classifier_as_a_Discriminator_Discriminator-Free_Adversarial_Domain_CVPR_2022_paper.pdf) \\
[Lin Chen](https://lin-chen.site/), [**Zhixiang Wei**](https://zxwei.site), [Xin Jin](https://www.eitech.edu.cn/?tid=40&p=teacher), [Enhong Chen](http://staff.ustc.edu.cn/~cheneh/).

[![](https://img.shields.io/github/stars/xiaoachen98/DALN?style=social&label=DALN+Stars)](https://github.com/xiaoachen98/DALN)
- We reuse the category classifier as a discriminator to form a discriminator-free adversarial learning framework.
</div>
</div>


